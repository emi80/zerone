\relax 
\citation{pmid24349523}
\citation{pmid24173036}
\citation{pmid18463634}
\citation{li2011}
\citation{pmid19505943}
\citation{pmid18798982}
\citation{pmid19772557}
\citation{pmid25223640}
\newlabel{^_1}{{}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\citation{psclb}
\citation{R}
\citation{pscla}
\citation{baum1966}
\citation{Dempster77maximumlikelihood}
\citation{1054010}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methods}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.1}}Emission model}{2}}
\newlabel{sub:emissions}{{{2.1}}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.2}}Discretization}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Using the ZINB distribution to model ChIP-seq data. Reads from the negative control dataset XX were mapped on the human genome and pooled in 300\nobreakspace  {}bp windows after removing duplicates. The histogram of the read counts is shown in black (no immunoprecipitation was performed in this experiment, so this variation corresponds to the `baseline'). The histograms in gray scales show the maximum likelihood fit of the Poisson, Negative Binomial (NB) and Zero-Inflated Negative Binomial (ZINB) distributions. The fit of the Poisson distribution (light gray) is poor. The NB distribution (medium gray) gives a good fit at the tail, but not for windows with 0 and 1 read. The ZINB distribution (dark gray) gives a good fit over the whole range. }}{2}}
\newlabel{fig:ZINB_fit}{{1}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.3}}Classifier}{2}}
\citation{pmid21059603}
\citation{pmid23103880}
\citation{Chang2011}
\citation{e1071}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Principal Component Analysis of the training dataset. Training examples labeled as positive (dark circles) appear to be similar to each other, while negative examples (light crosses) show notable differences between them and with respect to positive examples. There exist though a certain degree of overlap between the two groups that crates an ``ambiguous zone'', at least in this projection. }}{3}}
\newlabel{fig:pca}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.4}}Datasets and preprocessing}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.5}}Classifier training}{3}}
\newlabel{sub:training}{{{2.5}}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.6}}Benchmark conditions}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{3}}
\newlabel{sec:results}{{3}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{3.1}}Speed and memory consumption}{3}}
\citation{pmid17382889}
\citation{pmid21330290}
\citation{pmid19458158}
\citation{pmid24194598}
\citation{pmid}
\citation{pmid}
\bibstyle{natbib}
\bibdata{document,extra}
\bibcite{baum1966}{{1}{1966}{{Baum and Petrie}}{{Baum and Petrie}}}
\bibcite{Chang2011}{{2}{2011}{{Chang and Lin}}{{Chang and Lin}}}
\bibcite{Dempster77maximumlikelihood}{{3}{1977}{{Dempster {\em  et~al.}}}{{Dempster, Laird, and Rubin}}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Running times and memory footprint of the different discretizers on the three ChIP-seq datasets. For programs that only allow single-profile discretization (\textit  {i.e.} BayesPeak and MACS), mean values are shown. Note the logarithmic scale in the running times. }}{4}}
\newlabel{fig:perf}{{3}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{3.2}}Discretization benchmark}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {{{3.2}.1}}Identification of CTCF binding sites.}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {{{3.2}.2}}H3K36me3-enriched domains.}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {{{3.2}.3}}Pol2 binding around transcription start sites.}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Summary of peak calling on the CTCF dataset. The table lists the total number of peaks found by the different programs, how many of those peaks contained at least one CTCF motif, and the correspondent precision, recall and $F_{1}$ score relative to the CTCF motif dataset. }}{4}}
\newlabel{tab:ctcf}{{1}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Caption, caption.}}{4}}
\newlabel{fig:venn}{{4}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion and conclusion}{4}}
\@writefile{toc}{\contentsline {paragraph}{Funding\text  {\rm  :}}{4}}
\bibcite{pscla}{{4}{2015}{{Jackman}}{{Jackman}}}
\bibcite{li2011}{{5}{2011}{{Li {\em  et~al.}}}{{Li, Brown, Huang, and Bickel}}}
\bibcite{e1071}{{6}{2014}{{Meyer {\em  et~al.}}}{{Meyer, Dimitriadou, Hornik, Weingessel, and Leisch}}}
\bibcite{R}{{7}{2014}{{R Core Team}}{{R Core Team}}}
\bibcite{1054010}{{8}{1967}{{Viterbi}}{{Viterbi}}}
\bibcite{psclb}{{9}{2008}{{Zeileis {\em  et~al.}}}{{Zeileis, Kleiber, and Jackman}}}
\global\@namedef{@lastpage@}{5}
